{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from Make_Env import make_env\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = namedtuple(typename=\"transition\", \n",
    "            field_names=(\"state\", \"action\", \"reward\", \"done\", \"next_state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class buffer(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.buffer = []\n",
    "        self.pos = 0\n",
    "    \n",
    "    def store(self, *args):\n",
    "        if len(self.buffer) < self.size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.pos] = transition(*args)\n",
    "        self.pos = (self.pos + 1) % self.size\n",
    "    \n",
    "    def sample(self, batch):\n",
    "        return random.sample(self.buffer, batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : 84 * 84 * 4\n",
    "#  -> conv1 -> 20 * 20 * 32\n",
    "#  -> conv2 -> 9 * 9 * 64\n",
    "#  -> conv3 -> 7 * 7 * 64 \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_n = 4, action_n = 4):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = input_n, \n",
    "                      out_channels = 32, \n",
    "                      kernel_size = 8, \n",
    "                      stride = 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 32,\n",
    "                      out_channels = 64,\n",
    "                      kernel_size = 4,\n",
    "                      stride = 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64,\n",
    "                      out_channels = 64,\n",
    "                      kernel_size = 3,\n",
    "                      stride = 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(64 * 7 * 7, 512)\n",
    "        torch.nn.init.normal_(self.fc.weight, mean=0, std=1)\n",
    "        torch.nn.init.constant_(self.fc.bias, 0.1)\n",
    "        self.output = nn.Linear(512, action_n)\n",
    "        torch.nn.init.normal_(self.output.weight, mean=0, std=1)\n",
    "        torch.nn.init.constant_(self.output.bias, 0.1)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.float() / 128 - 1\n",
    "        s = self.conv1(s)\n",
    "        s = self.conv2(s)\n",
    "        s = self.conv3(s)\n",
    "        t = s.reshape(s.size(0), -1)\n",
    "        t = self.fc(t)\n",
    "        t = F.leaky_relu(t)\n",
    "        t = self.output(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, lr = 0.00025, buffer_size = 100000, T = 100, batch = 32, epsilon = 1.0, gamma = 0.99, load = False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "        self.buffer = buffer(buffer_size)\n",
    "        self.t = 0\n",
    "        self.T_count = 0\n",
    "        self.T = T\n",
    "        self.epsilon = epsilon\n",
    "        self.batch = batch\n",
    "        self.gamma = gamma\n",
    "        self.eval_net = Net().to(self.device)\n",
    "        self.target_net = Net().to(self.device)\n",
    "        self.loss_function = nn.SmoothL1Loss()\n",
    "        self.flag = 0\n",
    "        self.decay = 0\n",
    "        self.opt = torch.optim.Adam(self.eval_net.parameters(), lr = lr)\n",
    "        # self.decay = torch.optim.lr_scheduler.ExponentialLR(self.opt, gamma=0.99)\n",
    "        if load:\n",
    "            self.eval_net.load_state_dict(torch.load('dqn_evaluate_net.pth'))\n",
    "            self.target_net.load_state_dict(torch.load('dqn_target_net.pth'))\n",
    "    \n",
    "    def choose_action(self, s):\n",
    "        s = s.to(self.device)\n",
    "        if self.flag == 1 and self.decay == 0:\n",
    "            self.epsilon = np.exp(-self.t / 100000)\n",
    "            self.decay = 1\n",
    "        if self.epsilon < 0.05 and self.flag == 1:\n",
    "            print('......ready......')\n",
    "            self.flag = 2\n",
    "        if self.epsilon < 0.005:\n",
    "            self.epsilon = 0.005\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            action = torch.tensor([[random.randrange(4)]], device=self.device, dtype=torch.long)\n",
    "        else:\n",
    "            action = self.eval_net(s).detach().max(1)[1].view(1, 1)\n",
    "        return action\n",
    "    \n",
    "    def get_s(self, s):\n",
    "        s = np.array(s)\n",
    "        s = s.transpose((2, 0, 1))\n",
    "        s = torch.from_numpy(s)\n",
    "        return s.unsqueeze(0)\n",
    "\n",
    "    def learn(self):\n",
    "        if self.flag == 0:\n",
    "            print(\"......learning......\")\n",
    "            self.flag = 1\n",
    "        transitions = self.buffer.sample(self.batch)\n",
    "        batch = transition(*zip(*transitions))\n",
    "        b_a = tuple((map(lambda a : torch.tensor([[a]], device = self.device), batch.action)))\n",
    "        b_d = tuple((map(lambda d : torch.tensor([d], device = self.device), batch.done)))\n",
    "        b_r = tuple((map(lambda r : torch.tensor([r], device = self.device), batch.reward)))\n",
    "        b_a = torch.cat(b_a)\n",
    "        b_r = torch.cat(b_r)\n",
    "        b_d = torch.cat(b_d)\n",
    "        mask = (b_d == True)\n",
    "        b_s = torch.cat(batch.state).to(self.device)\n",
    "        b_s_ = torch.cat(batch.next_state).to(self.device)\n",
    "        Q_s = self.eval_net(b_s).gather(1, b_a).squeeze(-1)\n",
    "        Q_s_ = self.target_net(b_s_).max(1)[0].detach()\n",
    "        Q_estimate = b_r + self.gamma * Q_s_\n",
    "        Q_estimate[mask] = b_r[mask]\n",
    "        loss = self.loss_function(Q_estimate, Q_s)\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "    \n",
    "    def train(self, env, epoch = 400000):\n",
    "        score = []\n",
    "        max_score = []\n",
    "        m = 0\n",
    "        epi_score = 0\n",
    "        reward = 0\n",
    "        for i in range(epoch):\n",
    "            s = env.reset()\n",
    "            s = self.get_s(s)\n",
    "            self.t += 1\n",
    "            self.decay = 0\n",
    "            while True:\n",
    "                a = self.choose_action(s)\n",
    "                s_, r, done, info = env.step(a)\n",
    "                epi_score += r\n",
    "                s_ = self.get_s(s_)\n",
    "                self.buffer.store(s, a, r, done, s_)\n",
    "                if self.buffer.__len__() >= self.buffer.size:\n",
    "                    self.learn()\n",
    "                    self.T_count += 1\n",
    "                    if self.T_count % self.T == 0:\n",
    "                        self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "                s = s_\n",
    "                if done:\n",
    "                    break\n",
    "            if i % 5 == 0:\n",
    "                if epi_score > m:\n",
    "                    m = epi_score\n",
    "                score.append(epi_score)\n",
    "                reward += epi_score\n",
    "                epi_score = 0\n",
    "            if m > 100: \n",
    "                break\n",
    "            if i % 100 == 0:\n",
    "                print('episode: {} average score : {} max : {}'.format(i, reward / 20, m))\n",
    "                max_score.append(m)\n",
    "                m = 0\n",
    "                reward = 0   \n",
    "            if i % 200 == 0:\n",
    "                torch.save(self.eval_net.state_dict(), 'dqn_evaluate_net.pth')\n",
    "                torch.save(self.target_net.state_dict(), 'dqn_target_net.pth')\n",
    "            \n",
    "        plt.plot(max_score)\n",
    "        plt.ylabel('Max')\n",
    "        plt.show()\n",
    "        plt.savefig('dqn_max_score.jpg')\n",
    "        plt.close()\n",
    "        plt.plot(score, marker = 'o', markevery = 10)\n",
    "        plt.ylabel('episode_score')\n",
    "        plt.show()\n",
    "        plt.savefig('dqn_score.jpg')\n",
    "        plt.close()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Breakout-v4')\n",
    "env = make_env(env)\n",
    "env.seed(1)\n",
    "agent = Agent(load = True)\n",
    "agent.train(env)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e4379db7b16f55c483219118b705226f5953df2c8867cdf64099f9f3788ac64"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('shylockEnv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
